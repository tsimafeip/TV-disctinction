{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "bleurt_evaluation",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### This notebook is intended to evaluate [BLEURT](!https://github.com/google-research/bleurt) score of file translation."
   ],
   "metadata": {
    "id": "-h3LyAECEX74"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "# Install BLEURT and dependecies\n",
    "! pip install --upgrade pip  # ensures that pip is current\n",
    "! git clone https://github.com/google-research/bleurt.git\n",
    "! cd bleurt; pip3 install .\n",
    "\n",
    "# install checkpoint\n",
    "! wget https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip .\n",
    "! unzip BLEURT-20.zip\n",
    "! rm BLEURT-20.zip\n",
    "\n",
    "# wget for files downloading from git\n",
    "! pip install wget"
   ],
   "metadata": {
    "id": "vn30pqQtJTEY"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer"
   ],
   "metadata": {
    "id": "ndhoZUE_JUIJ"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Download files to score: candidate and reference\n",
    "git_path = r'https://raw.githubusercontent.com/tsimafeip/TV-distinction/main/'\n",
    "\n",
    "candidate_filename = 'base_model_no_labels'\n",
    "reference_filename = 'deixis_test_ru'\n",
    "\n",
    "candidate_git_path = os.path.join(git_path, 'translations', candidate_filename)\n",
    "reference_git_path = os.path.join(git_path, 'data', reference_filename)\n",
    "\n",
    "if not os.path.isfile(candidate_filename):\n",
    "    wget.download(candidate_git_path, candidate_filename)\n",
    "\n",
    "if not os.path.isfile(reference_filename):\n",
    "    wget.download(reference_git_path, reference_filename)"
   ],
   "metadata": {
    "id": "p4PtVw_-Esfs"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# BLEURT demo\n",
    "from bleurt import score\n",
    "\n",
    "bleurt_checkpoint = \"BLEURT-20\"\n",
    "\n",
    "candidates = [\n",
    "  \"К моему великолепному удивлению, ваш фингерпечатник запал в AFIS.\",\n",
    "  \"Конечно, они не являются.\",\n",
    "  \"Я никогда не совершил никаких преступлений.\",\n",
    "  \"Вы никогда не увидели.\",\n",
    "  \"Вы никогда не увидели.\",\n",
    "]\n",
    "references = [\n",
    "  \"К моему удивлению , твоих пальчиков не оказалось в АДИС .\",\n",
    "  \"Естественно . \",\n",
    "  \"Я никогда не нарушала закон . \",\n",
    "  \"Тебя не ловили .\",\n",
    "  \"Вас не ловили .\"\n",
    "]\n",
    "\n",
    "scorer = score.BleurtScorer(bleurt_checkpoint)\n",
    "scores = scorer.score(references=references, candidates=candidates)\n",
    "assert type(scores) == list and len(scores) == len(references)\n",
    "print(scores)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdZlTddmEXLq",
    "outputId": "ecf689b7-8728-4c66-dfaf-694120a190d7"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Reading checkpoint BLEURT-20.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: BLEURT-20/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "[0.3393818140029907, 0.1906919777393341, 0.7563686966896057, 0.33146679401397705, 0.3932281732559204]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# batching helps to avoid out-of-memory problem, caused by keeping the whole file in memory\n",
    "# we can also resume BLEURT evaluation\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "START_SENTENCE = 0\n",
    "scores_filename = candidate_filename + '.bleurt'\n",
    "scores = []\n",
    "\n",
    "with open(candidate_filename) as cand_file, \\\n",
    "    open(reference_filename) as ref_file, \\\n",
    "    open(scores_filename, 'w') as scores_file:\n",
    "    \n",
    "    candidates = cand_file.read().splitlines() \n",
    "    references = ref_file.read().splitlines()\n",
    "    assert len(candidates) == len(references)\n",
    "\n",
    "    start = timer()\n",
    "    i, j = 0, BATCH_SIZE\n",
    "    print(f\"Starting BLEURT evaluation of '{candidate_filename}' file ...\")\n",
    "    for i in tqdm(range(START_SENTENCE, len(candidates), BATCH_SIZE)):\n",
    "        cur_batch_candidates = candidates[i:i+BATCH_SIZE]\n",
    "        cur_batch_references = references[i:i+BATCH_SIZE]\n",
    "        #print(cur_batch_candidates, cur_batch_references)\n",
    "        batch_scores = scorer.score(references=cur_batch_references, candidates=cur_batch_candidates)\n",
    "        #print(batch_scores)\n",
    "        scores.extend(batch_scores)\n",
    "\n",
    "        scores_file.writelines([str(score) + '\\n' for score in batch_scores])\n",
    "    print(\"\\nFinished evaluation in : %f seconds\\n\" % (timer() - start))\n",
    "    print(f\"Average score: {sum(scores)/len(scores)}.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbKNuewbJ4jn",
    "outputId": "d0ba1c3e-22d8-4089-f9b4-713903aad808",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BLEURT evaluation of 'base_model_no_labels' file ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 303/303 [1:21:28<00:00, 16.13s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Finished evaluation in : 4888.077164 seconds\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  }
 ]
}