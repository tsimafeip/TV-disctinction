{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "demo_TV_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Steps to apply demo after training\n",
        "1. Tweak config file from models dir\n",
        "  - Change models dir name to *'models'* str.\n",
        "  - Comment path to the checkpoint file.\n",
        "\n",
        "2. Manually create non_cuda config by changing a *'use_cuda'* flag to False in config file from 1st step. Name it *'config_non_cuda.yaml'* and put to the same *'models'* folder.\n",
        "\n",
        "3. Change filename  for best checkpoint to *'TV.ckpt'*. For example, rename *'344000.ckpt'* to *'TV.ckpt'*."
      ],
      "metadata": {
        "id": "QOjul-TLoBKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXbZ6v7oklng",
        "outputId": "e0a416f4-b616-42a0-e0cb-05ef9921af4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqdEumRjUuNG"
      },
      "source": [
        "%%capture\n",
        "# installing sacremoses - tokenization library\n",
        "! pip install sacremoses\n",
        "# wget - for files dowloading from git\n",
        "! pip install wget\n",
        "\n",
        "# cloning joeynmt and installing dependecies\n",
        "! git clone https://github.com/joeynmt/joeynmt.git\n",
        "! cd joeynmt; pip3 install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wget\n",
        "from timeit import default_timer as timer"
      ],
      "metadata": {
        "id": "CwEqMSEizyd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting main parameters.\n",
        "# Set use cuda to True for file translation\n",
        "use_cuda = True\n",
        "# root directory name with 'data' and 'models' subfolders left after training\n",
        "model_name = 'joeynmt_en_ru_TV'\n",
        "# name of the best chekpoint after training\n",
        "best_ckpt_name = 'TV.ckpt'"
      ],
      "metadata": {
        "id": "rrm9FmR109v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up helper variables, please ignore hardcode\n",
        "runtime_path = \"/content/drive/MyDrive/TV_project/{}\".format(model_name)\n",
        "bpe_codes_file = 'bpe.codes.5000'\n",
        "source_tc_model = 'en.txt_tc.model'\n",
        "source_vocab_file = 'vocab.en'\n",
        "\n",
        "os.environ[\"runtime_path\"] = runtime_path\n",
        "os.environ[\"model_name\"] = model_name\n",
        "os.environ[\"best_ckpt_name\"] = best_ckpt_name\n",
        "os.environ[\"bpe_codes_file\"] = bpe_codes_file\n",
        "os.environ[\"source_tc_model\"] = source_tc_model\n",
        "os.environ[\"source_vocab_file\"] = source_vocab_file\n",
        "! echo $runtime_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93F44GaGkxfg",
        "outputId": "20c90f98-7db8-4111-d3ec-ef05fc1cfd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TV_project/en-ru-TV_basic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1GuIR88g3p_",
        "outputId": "61f8991b-fec4-475d-adf1-dcd0dde8aa2b"
      },
      "source": [
        "# testing if joeynmt installed correctly\n",
        "! cd joeynmt; python3 -m unittest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "................................s.........................\n",
            "----------------------------------------------------------------------\n",
            "Ran 58 tests in 4.613s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path to the joeynmt data and model folder\n",
        "# here you see default values, \n",
        "# but we can add metainfo about lang pairs or architecture to the path\n",
        "joeynmt_models_folder = 'joeynmt/models/'\n",
        "joeynmt_data_folder = 'joeynmt/data/'\n",
        "\n",
        "os.environ[\"joeynmt_models_folder\"] = joeynmt_models_folder\n",
        "os.environ[\"joeynmt_data_folder\"] = joeynmt_data_folder"
      ],
      "metadata": {
        "id": "psimoHRinVoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzx_OGVZIt4G"
      },
      "source": [
        "# copying data from runtime folder to joeynmt\n",
        "! mkdir -p \"$joeynmt_models_folder\"\n",
        "! cp -r \"$runtime_path\"/models/config.yaml \"$joeynmt_models_folder\"\n",
        "! cp -r \"$runtime_path\"/models/config_non_cuda.yaml \"$joeynmt_models_folder\"\n",
        "! cp -r \"$runtime_path\"/models/\"$best_ckpt_name\" \"$joeynmt_models_folder\"\n",
        "! mkdir -p \"$joeynmt_data_folder\" && cp -r \"$runtime_path/data/\"* \"$joeynmt_data_folder\"\n",
        "! cp -r \"$joeynmt_data_folder\"/\"$source_tc_model\" ./\n",
        "! cp -r \"$joeynmt_data_folder\"/\"$bpe_codes_file\" ./\n",
        "! cp -r \"$joeynmt_data_folder\"/\"$source_vocab_file\" ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwk1hogjNFmF"
      },
      "source": [
        "# Functions to test translation quality in two modes: 'interactive' and 'file'.\n",
        "from sacrebleu import corpus_bleu\n",
        "\n",
        "def interactive_translate(text: str, tokenised_input: bool = False):\n",
        "    \"\"\"\n",
        "    Translates input text. \n",
        "    Non_cuda mode recommended to avoid extensive installation of cuda packages.\n",
        "    \"\"\"\n",
        "    os.environ[\"config\"] = \"config.yaml\" if use_cuda else \"config_non_cuda.yaml\"\n",
        "    if not tokenised_input:\n",
        "        ! echo \"$text\" | sacremoses tokenize | sacremoses truecase -m \"$source_tc_model\" | subword-nmt apply-bpe -c \"$bpe_codes_file\" --vocabulary \"$source_vocab_file\" > \"joeynmt/in.txt\"\n",
        "    else:\n",
        "        ! echo \"$text\" | sacremoses truecase -m \"$source_tc_model\" | subword-nmt apply-bpe -c \"$bpe_codes_file\" --vocabulary \"$source_vocab_file\" > \"joeynmt/in.txt\"\n",
        "    ! cd joeynmt; python3 -m joeynmt translate \"$runtime_path/models/$config\" < in.txt 2> /dev/null | sacremoses detruecase 2> /dev/null | sacremoses detokenize 2> /dev/null | sed \"s/ '/'/\" | sed \"s/' /'/\"\n",
        "\n",
        "\n",
        "# use_cuda = true is strongly recommended for file translation!\n",
        "def file_translate(file: str, tokenised_input: bool = True) -> str:\n",
        "    \"\"\"Accepts file to trainslate and returns translation result.\"\"\"\n",
        "    os.environ[\"config\"] = \"config.yaml\" if use_cuda else \"config_non_cuda.yaml\"\n",
        "    ! sed -i 's/\"//g' \"$file\"\n",
        "    if not tokenised_input:\n",
        "        ! sacremoses tokenize < \"$file\" | sacremoses truecase -m \"$source_tc_model\" | subword-nmt apply-bpe -c \"$bpe_codes_file\" --vocabulary \"$source_vocab_file\" > \"joeynmt/in.txt\"\n",
        "    else:\n",
        "        ! cat \"$file\" | sacremoses truecase -m \"$source_tc_model\" | subword-nmt apply-bpe -c \"$bpe_codes_file\" --vocabulary \"$source_vocab_file\" > \"joeynmt/in.txt\"\n",
        "    ! cd joeynmt; python3 -m joeynmt translate \"$runtime_path/models/$config\" < in.txt 2> /dev/null | sacremoses detruecase 2> /dev/null | sacremoses detokenize 2> /dev/null | sed \"s/ '/'/\" | sed \"s/' /'/\" > \"joey_pred.txt\"\n",
        "    outfile = f\"{file}_pred\"\n",
        "    os.rename(os.path.join('joeynmt', 'joey_pred.txt'), outfile)\n",
        "    return outfile\n",
        "\n",
        "\n",
        "def get_bleu(reference_file: str, prediction_file: str) -> float:\n",
        "    \"\"\"Calculates BLEU metric for two provided files.\"\"\"\n",
        "    with open(reference_file, 'r', encoding=\"utf-8\") as reference_f, \\\n",
        "            open(prediction_file, 'r', encoding=\"utf-8\") as prediction_f:\n",
        "        real = reference_f.readlines()\n",
        "        prediction = prediction_f.readlines()\n",
        "\n",
        "    return corpus_bleu(prediction, [real]).score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactive_translate('Where are you going ?', tokenised_input=True)\n",
        "interactive_translate('Where are you going?', tokenised_input=False)\n",
        "\n",
        "# It is extremely important to disable tokenization for sentences with <T>, <V> labels \n",
        "interactive_translate('<T> Where are you going ?', tokenised_input=True)\n",
        "interactive_translate('<T> Where are you going?', tokenised_input=False)\n",
        "\n",
        "interactive_translate('<V> Where are you going ?', tokenised_input=True)\n",
        "interactive_translate('<V> Where are you going?', tokenised_input=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpZGAtT41Jpj",
        "outputId": "6f74069a-0403-436e-d5a9-4e404dbaf812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Где идет?\n",
            "Где идет?\n",
            "Где ты идешь?\n",
            "< T > Wздесь идет?\n",
            "Где вы идете?\n",
            "< V > Wздесь идет?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtUNT_0j1c2u"
      },
      "source": [
        "%%capture\n",
        "# installing cuda\n",
        "if use_cuda:\n",
        "    !wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
        "    !sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "    !sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
        "    !sudo add-apt-repository \"deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /\"\n",
        "    !sudo apt-get update\n",
        "    !sudo apt-get -y install cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load test data\n",
        "git_path = r'https://raw.githubusercontent.com/tsimafeip/TV-distinction/main/data/'\n",
        "\n",
        "source_test_filename = 'deixis_test_en.tv'\n",
        "target_test_filename = 'deixis_test_ru'\n",
        "\n",
        "test_source_git_path = git_path + source_test_filename\n",
        "test_target_git_path = git_path + target_test_filename\n",
        "\n",
        "if not os.path.isfile(source_test_filename):\n",
        "    wget.download(test_source_git_path, source_test_filename)\n",
        "\n",
        "if not os.path.isfile(target_test_filename):\n",
        "    wget.download(test_target_git_path, target_test_filename)"
      ],
      "metadata": {
        "id": "N_Ka-ODd-MCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f--UiR9wvID2",
        "outputId": "6395f88d-276d-4d35-9c85-f54032fef5d7"
      },
      "source": [
        "# Running file translation\n",
        "start = timer()\n",
        "print(f\"Started translation of {source_test_filename} ...\")\n",
        "pred_file = file_translate(source_test_filename)\n",
        "print(f\"Deixis Test BLEU: {get_bleu(target_test_filename, pred_file)}.\")\n",
        "print(\"\\nFinished translation in : %f seconds\\n\" % (timer() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started translation of deixis_test_en.tv ...\n",
            "Deixis Test BLEU: 15.142489874395736.\n",
            "\n",
            "Finished translation in : 370.469855 seconds\n",
            "\n"
          ]
        }
      ]
    }
  ]
}