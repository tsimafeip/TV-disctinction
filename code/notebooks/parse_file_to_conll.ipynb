{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "TV_distinction.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# T/V parsing\n",
    "\n",
    "This notebook is designed for the single target - parse test file in Russian language to [CoNLL](https://universaldependencies.org/format.html) format. Output of parsing is later used to label sentences with T/V tags based on set of heuristics.\n",
    "\n",
    "We use [DeepPavlov model](!http://docs.deeppavlov.ai/en/master/features/models/syntaxparser.html) for joint syntactic and morphological parsing and [conllu package](https://pypi.org/project/conllu/) to parse the output of the model."
   ],
   "metadata": {
    "id": "13tM-zZjeE3-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How to run this notebook\n",
    "\n",
    "- Use Google Colaboratory. This step helps to save space on local runtime and avoid painful dependency conflicts.\n",
    "\n",
    "- Package installation (1st cell) and model building (4th cell) take some time, so, please, be patient.\n",
    "\n",
    "- Please, remove '%%capture' and inspect installation logs in case of any errors on parsing."
   ],
   "metadata": {
    "id": "pGe1c4P1S7AT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "! pip install deeppavlov\n",
    "! python -m deeppavlov install syntax_ru_syntagrus_bert\n",
    "! pip install russian-tagsets\n",
    "! pip install conllu\n",
    "! pip install wget"
   ],
   "metadata": {
    "id": "b3wr-O7GJKIT"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # This step is required to override some default Colab packages \n",
    "# # with other versions installed from deeppavlov requirements.\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ],
   "metadata": {
    "id": "TgUmP5_2v34h"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import wget\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "from typing import Tuple, List, Set, Union, Optional\n",
    "\n",
    "import deeppavlov\n",
    "from deeppavlov import build_model, configs\n",
    "import conllu\n",
    "from conllu import parse as parse_conllu"
   ],
   "metadata": {
    "id": "_guT8hNliXkT"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "model = build_model(\"ru_syntagrus_joint_parsing\", download=True)"
   ],
   "metadata": {
    "id": "3h5vlVhNJmmk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d26fe169-0c38-475e-97f1-ad215582efbd"
   },
   "execution_count": 2,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 13:04:26.889 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'ru_syntagrus_joint_parsing' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/syntax/ru_syntagrus_joint_parsing.json'\n",
      "2022-03-27 13:04:27.662 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz to /root/.deeppavlov/downloads/rubert_cased_L-12_H-768_A-12_v1.tar.gz\n",
      "2022-03-27 13:04:52.68 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/downloads/rubert_cased_L-12_H-768_A-12_v1.tar.gz archive into /root/.deeppavlov/downloads/bert_models\n",
      "2022-03-27 13:05:00.772 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/BERT/morpho_ru_syntagrus_bert.tar.gz to /root/.deeppavlov/models/morpho_ru_syntagrus_bert.tar.gz\n",
      "2022-03-27 13:05:25.958 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/models/morpho_ru_syntagrus_bert.tar.gz archive into /root/.deeppavlov/models/morpho_ru_syntagrus\n",
      "2022-03-27 13:05:36.120 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/syntax_parser/syntax_ru_syntagrus_bert.tar.gz to /root/.deeppavlov/models/syntax_ru_syntagrus_bert.tar.gz\n",
      "2022-03-27 13:06:00.890 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/models/syntax_ru_syntagrus_bert.tar.gz archive into /root/.deeppavlov/models/syntax_ru_syntagrus\n",
      "2022-03-27 13:06:10.15 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/UD2.3/ru_syntagrus.tar.gz to /root/.deeppavlov/downloads/UD2.3_source/ru_syntagrus.tar.gz\n",
      "2022-03-27 13:06:11.897 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/downloads/UD2.3_source/ru_syntagrus.tar.gz archive into /root/.deeppavlov/downloads/UD2.3_source/ru_syntagrus\n",
      "2022-03-27 13:06:18.113 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/morpho_ru_syntagrus/tag.dict]\n",
      "2022-03-27 13:06:47.126 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/morpho_ru_syntagrus/model]\n",
      "2022-03-27 13:06:49.246 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
      "2022-03-27 13:06:49.782 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/syntax_ru_syntagrus/deps.dict]\n",
      "2022-03-27 13:07:21.825 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/syntax_ru_syntagrus/model_joint]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_sentences = [\"Вы увидитесь завтра.\", \"Ты увидишься завтра.\"]\n",
    "\n",
    "for conll_str in model(test_sentences):\n",
    "    print(conll_str, end=\"\\n\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mam0diRiXNiH",
    "outputId": "a7738ac0-ce55-405b-ff42-e8b42890f6c7"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\tВы\tвы\tPRON\t_\tCase=Nom|Number=Plur|Person=2\t2\tnsubj\t_\t_\n",
      "2\tувидитесь\tувидеться\tVERB\t_\tAspect=Perf|Mood=Ind|Number=Plur|Person=2|Tense=Fut|VerbForm=Fin|Voice=Mid\t0\troot\t_\t_\n",
      "3\tзавтра\tзавтра\tADV\t_\tDegree=Pos\t2\tadvmod\t_\t_\n",
      "4\t.\t.\tPUNCT\t_\t_\t2\tpunct\t_\t_\n",
      "\n",
      "1\tТы\tты\tPRON\t_\tCase=Nom|Number=Sing|Person=2\t2\tnsubj\t_\t_\n",
      "2\tувидишься\tувидеться\tVERB\t_\tAspect=Perf|Mood=Ind|Number=Sing|Person=2|Tense=Fut|VerbForm=Fin|Voice=Mid\t0\troot\t_\t_\n",
      "3\tзавтра\tзавтра\tADV\t_\tDegree=Pos\t2\tadvmod\t_\t_\n",
      "4\t.\t.\tPUNCT\t_\t_\t2\tpunct\t_\t_\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# load test data\n",
    "git_path = r'https://raw.githubusercontent.com/tsimafeip/TV-distinction/main/'\n",
    "\n",
    "test_filename = 'tv_model_oracle_labels'\n",
    "test_gitpath = os.path.join(git_path, 'translations', test_filename)\n",
    "\n",
    "if not os.path.isfile(test_filename):\n",
    "    wget.download(test_gitpath, test_filename)"
   ],
   "metadata": {
    "id": "kOhwCm_9f64Y"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# batching helps to avoid out-of-memory problems \n",
    "BATCH_SIZE = 100\n",
    "START_SENTENCE = 0\n",
    "\n",
    "with open(test_filename) as input_file, open(test_filename + '.conll', 'w') as conll_file:\n",
    "\n",
    "    input_lines = input_file.read().splitlines()\n",
    "    \n",
    "    start = timer()\n",
    "    i, j = 0, BATCH_SIZE\n",
    "    print(f\"Started parsing of {len(input_lines)} sentences ...\")\n",
    "    for i in tqdm(range(START_SENTENCE, len(input_lines), BATCH_SIZE)):\n",
    "        cur_batch = input_lines[i:i+BATCH_SIZE]\n",
    "        # we add comments (sentence id and text) for each set of conll lines:\n",
    "        # sent_id = 1\n",
    "        # text = They buy and sell books.\n",
    "        conllu_lines = []\n",
    "        for k, conll_line in enumerate(model(cur_batch)):\n",
    "            header = f\"# sent_id = {i+k}\\n\" + f\"# text = {cur_batch[k]}\\n\"\n",
    "            conllu_lines.append(header + conll_line + \"\\n\\n\")\n",
    "         \n",
    "        conll_file.writelines(conllu_lines)\n",
    "    print(\"\\nFinished parsing in : %f seconds\\n\" % (timer() - start))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1E3J614AuBSh",
    "outputId": "b7974791-19fd-4f7b-abbb-a3ba7711ab62"
   },
   "execution_count": null,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing of 9684 sentences ...\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [1:00:26<06:42, 402.83s/it]"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# CoNNL parsing demo \n",
    "test_sentences = [\"Вы увидите Вашего сына.\", \"Ты увидишь твоего сына\"]\n",
    "\n",
    "for conll_str in model(test_sentences):\n",
    "    print(conll_str, end=\"\\n\\n\")\n",
    "    conll_token_list = parse_conllu(conll_str)[0]\n",
    "    print(conll_token_list.to_tree().print_tree())\n",
    "    conll_token_list = conll_token_list.filter(upos=lambda x: x in {'PRON', 'DET', 'VERB'})\n",
    "    sample_token = conll_token_list[0]\n",
    "    for sample_token in conll_token_list[:3]:\n",
    "        print(sample_token, type(sample_token))\n",
    "        print(sample_token.items())\n",
    "    print()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MfOTVXsFylX2",
    "outputId": "586ee59c-bc50-4636-e03f-7c19db7b8d52"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\tВы\tвы\tPRON\t_\tCase=Nom|Number=Plur|Person=2\t2\tnsubj\t_\t_\n",
      "2\tувидите\tувидеть\tVERB\t_\tAspect=Perf|Mood=Ind|Number=Plur|Person=2|Tense=Fut|VerbForm=Fin|Voice=Act\t0\troot\t_\t_\n",
      "3\tВашего\tваш\tDET\t_\tCase=Acc|Gender=Masc|Number=Sing\t4\tdet\t_\t_\n",
      "4\tсына\tсын\tNOUN\t_\tAnimacy=Anim|Case=Acc|Gender=Masc|Number=Sing\t2\tobj\t_\t_\n",
      "5\t.\t.\tPUNCT\t_\t_\t2\tpunct\t_\t_\n",
      "\n",
      "(deprel:root) form:увидите lemma:увидеть upos:VERB [2]\n",
      "    (deprel:nsubj) form:Вы lemma:вы upos:PRON [1]\n",
      "    (deprel:obj) form:сына lemma:сын upos:NOUN [4]\n",
      "        (deprel:det) form:Вашего lemma:ваш upos:DET [3]\n",
      "    (deprel:punct) form:. lemma:. upos:PUNCT [5]\n",
      "None\n",
      "Вы <class 'conllu.models.Token'>\n",
      "dict_items([('id', 1), ('form', 'Вы'), ('lemma', 'вы'), ('upos', 'PRON'), ('xpos', None), ('feats', {'Case': 'Nom', 'Number': 'Plur', 'Person': '2'}), ('head', 2), ('deprel', 'nsubj'), ('deps', None), ('misc', None)])\n",
      "увидите <class 'conllu.models.Token'>\n",
      "dict_items([('id', 2), ('form', 'увидите'), ('lemma', 'увидеть'), ('upos', 'VERB'), ('xpos', None), ('feats', {'Aspect': 'Perf', 'Mood': 'Ind', 'Number': 'Plur', 'Person': '2', 'Tense': 'Fut', 'VerbForm': 'Fin', 'Voice': 'Act'}), ('head', 0), ('deprel', 'root'), ('deps', None), ('misc', None)])\n",
      "Вашего <class 'conllu.models.Token'>\n",
      "dict_items([('id', 3), ('form', 'Вашего'), ('lemma', 'ваш'), ('upos', 'DET'), ('xpos', None), ('feats', {'Case': 'Acc', 'Gender': 'Masc', 'Number': 'Sing'}), ('head', 4), ('deprel', 'det'), ('deps', None), ('misc', None)])\n",
      "\n",
      "1\tТы\tты\tPRON\t_\tCase=Nom|Number=Sing|Person=2\t2\tnsubj\t_\t_\n",
      "2\tувидишь\tувидеть\tVERB\t_\tAspect=Perf|Mood=Ind|Number=Sing|Person=2|Tense=Fut|VerbForm=Fin|Voice=Act\t0\troot\t_\t_\n",
      "3\tтвоего\tтвой\tDET\t_\tCase=Acc|Gender=Masc|Number=Sing\t4\tdet\t_\t_\n",
      "4\tсына\tсын\tNOUN\t_\tAnimacy=Anim|Case=Acc|Gender=Masc|Number=Sing\t2\tobj\t_\t_\n",
      "\n",
      "(deprel:root) form:увидишь lemma:увидеть upos:VERB [2]\n",
      "    (deprel:nsubj) form:Ты lemma:ты upos:PRON [1]\n",
      "    (deprel:obj) form:сына lemma:сын upos:NOUN [4]\n",
      "        (deprel:det) form:твоего lemma:твой upos:DET [3]\n",
      "None\n",
      "Ты <class 'conllu.models.Token'>\n",
      "dict_items([('id', 1), ('form', 'Ты'), ('lemma', 'ты'), ('upos', 'PRON'), ('xpos', None), ('feats', {'Case': 'Nom', 'Number': 'Sing', 'Person': '2'}), ('head', 2), ('deprel', 'nsubj'), ('deps', None), ('misc', None)])\n",
      "увидишь <class 'conllu.models.Token'>\n",
      "dict_items([('id', 2), ('form', 'увидишь'), ('lemma', 'увидеть'), ('upos', 'VERB'), ('xpos', None), ('feats', {'Aspect': 'Perf', 'Mood': 'Ind', 'Number': 'Sing', 'Person': '2', 'Tense': 'Fut', 'VerbForm': 'Fin', 'Voice': 'Act'}), ('head', 0), ('deprel', 'root'), ('deps', None), ('misc', None)])\n",
      "твоего <class 'conllu.models.Token'>\n",
      "dict_items([('id', 3), ('form', 'твоего'), ('lemma', 'твой'), ('upos', 'DET'), ('xpos', None), ('feats', {'Case': 'Acc', 'Gender': 'Masc', 'Number': 'Sing'}), ('head', 4), ('deprel', 'det'), ('deps', None), ('misc', None)])\n",
      "\n"
     ]
    }
   ]
  }
 ]
}